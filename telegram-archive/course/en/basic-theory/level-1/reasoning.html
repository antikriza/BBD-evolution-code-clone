<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>Reasoning - Basic Theory</title>
<style>
* { margin:0; padding:0; box-sizing:border-box; }
body { font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, sans-serif; background:#0a0a0f; color:#e4e6eb; }
a { color:#6ab2f2; text-decoration:none; }
a:hover { text-decoration:underline; }
.header { background:#111119; padding:16px 24px; border-bottom:1px solid #1e1e2e; display:flex; align-items:center; gap:16px; position:sticky; top:0; z-index:10; }
.header h1 { font-size:18px; color:#6ab2f2; }
.header .back { color:#8696a4; font-size:14px; }
.header .lang-switch { margin-left:auto; font-size:13px; color:#8696a4; }
.container { max-width:900px; margin:0 auto; padding:24px; }
.breadcrumb { color:#8696a4; font-size:13px; margin-bottom:20px; }
.breadcrumb a { color:#6ab2f2; }
.level-badge { display:inline-block; padding:4px 12px; border-radius:20px; font-size:12px; font-weight:600; margin-bottom:16px; }
.level-1 { background:rgba(74,222,128,0.15); color:#4ade80; }
.level-2 { background:rgba(96,165,250,0.15); color:#60a5fa; }
.level-3 { background:rgba(245,158,11,0.15); color:#f59e0b; }
.level-4 { background:rgba(239,68,68,0.15); color:#ef4444; }
.level-5 { background:rgba(168,85,247,0.15); color:#a855f7; }
h2 { font-size:28px; margin-bottom:8px; }
.desc { color:#8696a4; font-size:15px; line-height:1.7; margin-bottom:24px; }
.detail-list { list-style:none; padding:0; }
.detail-list li { padding:10px 16px; margin-bottom:6px; border-radius:8px; background:#111119; border-left:3px solid #2b5278; font-size:14px; line-height:1.5; color:#e4e6eb; }
.detail-list li::before { content:'\2192 '; color:#6ab2f2; }
.section-title { font-size:16px; color:#8696a4; margin:24px 0 12px; text-transform:uppercase; letter-spacing:1px; }
.related-topics { display:flex; gap:8px; flex-wrap:wrap; margin-top:8px; }
.related-topics a { display:inline-block; background:#111119; border:1px solid #1e1e2e; padding:6px 14px; border-radius:8px; font-size:13px; color:#6ab2f2; }
.related-topics a:hover { background:#1e1e2e; text-decoration:none; }
.nav-links { display:flex; justify-content:space-between; margin-top:30px; padding-top:20px; border-top:1px solid #1e1e2e; }
.nav-links a { color:#6ab2f2; font-size:14px; }
.nav-links .disabled { color:#333; }
.topic-grid { display:grid; grid-template-columns:repeat(auto-fill, minmax(260px, 1fr)); gap:12px; margin-top:16px; }
.topic-card { background:#111119; border-radius:12px; padding:18px; border-left:3px solid #2b5278; display:block; transition:background 0.15s; }
.topic-card:hover { background:#1a1a2e; text-decoration:none; }
.topic-card h3 { color:#e4e6eb; font-size:15px; margin-bottom:4px; }
.topic-card .sub { color:#8696a4; font-size:13px; }
.footer { text-align:center; padding:30px; color:#8696a4; font-size:12px; margin-top:30px; border-top:1px solid #1e1e2e; }
.overview { margin-bottom:28px; }
.overview p { color:#c4c6cb; font-size:15px; line-height:1.8; margin-bottom:14px; }
.terms-grid { display:grid; gap:10px; margin-top:12px; }
.term-card { background:#111119; border:1px solid #1e1e2e; border-radius:10px; padding:14px 18px; }
.term-card strong { color:#6ab2f2; font-size:14px; }
.term-card span { color:#c4c6cb; font-size:13px; display:block; margin-top:4px; line-height:1.5; }
.tip-box { background:linear-gradient(135deg, rgba(106,178,242,0.06), rgba(106,178,242,0.02)); border:1px solid rgba(106,178,242,0.15); border-radius:10px; padding:16px 20px; margin-top:12px; }
.tip-box li { color:#c4c6cb; font-size:14px; line-height:1.6; margin-bottom:8px; list-style:none; }
.tip-box li::before { content:'üí° '; }
.detail-card { background:#111119; border-radius:10px; padding:16px 18px; margin-bottom:8px; border-left:3px solid #2b5278; }
.detail-card .dt { color:#e4e6eb; font-size:14px; font-weight:600; margin-bottom:4px; }
.detail-card .dd { color:#9ca3af; font-size:13px; line-height:1.6; }
.detail-card .dl { margin-top:6px; }
.detail-card .dl a { font-size:12px; color:#6ab2f2; background:rgba(106,178,242,0.08); padding:3px 10px; border-radius:6px; display:inline-block; margin-right:6px; margin-top:4px; }
.detail-card .dl a:hover { background:rgba(106,178,242,0.15); text-decoration:none; }
</style>
</head>
<body>
<div class="header">
  <a href="../../index.html" class="back">&larr; Back to Course</a>
  <h1>Basic Theory</h1>
  <a href="../../../uk/basic-theory/level-1/reasoning.html" class="lang-switch">üá∫üá¶ –£–∫—Ä–∞—ó–Ω—Å—å–∫–∞</a>
</div>
<div class="container">
  <div class="breadcrumb"><a href="../../index.html">Course</a> / <a href="../index.html">Basic Theory</a> / <a href="index.html">Level 1</a> / Reasoning</div>
  <span class="level-badge level-1">üå± Level 1 ‚Äî Beginner</span>
  <h2>Reasoning</h2>
  <p class="desc">AI reasoning capabilities - chain of thought, thinking models, and logical inference.</p>

  <div class="overview">
    <p>Reasoning is one of the most important and rapidly evolving capabilities of modern AI. While early LLMs could generate fluent text, they often struggled with multi-step logic, math, and complex problem-solving. The introduction of chain-of-thought prompting and dedicated reasoning models has dramatically improved these capabilities.</p>
    <p>Models like OpenAI o1/o3, DeepSeek-R1, and QwQ use &quot;thinking tokens&quot; ‚Äî they reason step-by-step internally before producing a final answer. This mirrors the human distinction between fast intuitive thinking (System 1) and slow deliberate reasoning (System 2). Understanding these capabilities and their limits is crucial for knowing when to trust AI outputs.</p>
  </div>
  <div class="section-title">Key Topics Covered</div>
  <div class="detail-cards">
    <div class="detail-card"><div class="dt">Chain-of-Thought (CoT) Prompting</div><div class="dd">Asking models to &quot;think step by step&quot; dramatically improves accuracy on complex problems. Instead of jumping to answers, the model shows its work ‚Äî breaking problems into manageable steps.</div><div class="dl"><a href="../level-4/prompting-techniques.html">Prompting Techniques</a><a href="../level-2/prompt.html">Prompt</a></div></div>
    <div class="detail-card"><div class="dt">Reasoning Models</div><div class="dd">OpenAI o1/o3, DeepSeek-R1, QwQ (Alibaba) are specifically trained for multi-step reasoning. They use extra inference-time compute to &quot;think longer&quot; before answering.</div><div class="dl"><a href="big-players.html">The Big Players</a></div></div>
    <div class="detail-card"><div class="dt">Thinking Tokens</div><div class="dd">Internal reasoning traces generated before the final answer. These tokens are the model's &quot;scratch pad&quot; ‚Äî working through logic, checking steps, considering alternatives.</div><div class="dl"><a href="../level-2/token.html">Token</a></div></div>
    <div class="detail-card"><div class="dt">Extended Thinking</div><div class="dd">Allocating more compute at inference time for harder problems. The model can &quot;think longer&quot; on complex questions, trading speed for accuracy. Test-time compute scaling.</div></div>
    <div class="detail-card"><div class="dt">Math Reasoning</div><div class="dd">Solving competition-level math (AIME, AMC), formal proofs, symbolic manipulation. Reasoning models have made dramatic progress here ‚Äî approaching human expert level.</div><div class="dl"><a href="sota.html">SOTA</a></div></div>
    <div class="detail-card"><div class="dt">Code Reasoning</div><div class="dd">Debugging complex codebases, analyzing architecture, implementing sophisticated algorithms. Code reasoning is one of the most practically valuable AI capabilities.</div><div class="dl"><a href="../level-2/vibecoding.html">Vibecoding</a></div></div>
    <div class="detail-card"><div class="dt">Logical Inference</div><div class="dd">Syllogisms, deduction, constraint satisfaction, planning. Models can follow logical rules but still struggle with certain types of novel reasoning and common-sense physics.</div></div>
    <div class="detail-card"><div class="dt">System 1 vs System 2 Thinking</div><div class="dd">Kahneman's framework applied to AI: System 1 = fast intuitive responses (standard LLM), System 2 = slow deliberate reasoning (reasoning models with thinking tokens).</div></div>
    <div class="detail-card"><div class="dt">Current Limitations</div><div class="dd">Reasoning models still fail on truly novel problems, can produce convincing but wrong chains of reasoning, and may overthink simple questions. Verification remains essential.</div><div class="dl"><a href="../level-2/hallucination.html">Hallucinations</a></div></div>
    <div class="detail-card"><div class="dt">Reasoning Benchmarks</div><div class="dd">MATH (competition math), GSM8K (grade school), ARC-AGI (general reasoning), SWE-bench (real software engineering), Codeforces (competitive programming).</div><div class="dl"><a href="sota.html">SOTA</a></div></div>
  </div>

  <div class="section-title">Key Terms</div>
  <div class="terms-grid">
    <div class="term-card"><strong>Chain-of-Thought</strong><span>Technique where models explain their reasoning step-by-step before giving an answer.</span></div>
    <div class="term-card"><strong>Thinking Tokens</strong><span>Internal reasoning traces generated by reasoning models before the final output.</span></div>
    <div class="term-card"><strong>System 1/System 2</strong><span>Kahneman's framework: fast intuitive vs slow deliberate thinking, applied to AI.</span></div>
    <div class="term-card"><strong>Test-Time Compute</strong><span>Allocating more processing at inference time to improve reasoning on harder problems.</span></div>
  </div>

  <div class="section-title">Practical Tips</div>
  <div class="tip-box"><ul>
    <li>For complex problems, explicitly ask the model to &quot;think step by step&quot; ‚Äî this simple instruction activates chain-of-thought reasoning and can double accuracy on math and logic tasks</li>
    <li>Reasoning models (o1, Claude with extended thinking) cost more and are slower ‚Äî use them for hard problems, and faster models for simple tasks</li>
    <li>If a model gives a wrong answer, try breaking the problem into smaller sub-questions rather than just asking again ‚Äî decomposition often fixes reasoning failures</li>
  </ul></div>

    <div class="section-title">Related Community Discussions</div>
    <div class="related-topics">
      <a href="#">Models</a>
      <a href="#">Feed</a>
    </div>

  <div class="nav-links">
    <a href="multimodality.html">&larr; Multimodality</a>
    <a href="foundation-models.html">Foundation Models &rarr;</a>
  </div>
</div>
<div class="footer"><a href="../../index.html">&larr; Back to Course</a></div>
</body>
</html>