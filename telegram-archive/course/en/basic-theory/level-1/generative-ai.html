<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>Generative AI - Basic Theory</title>
<style>
* { margin:0; padding:0; box-sizing:border-box; }
body { font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, sans-serif; background:#0a0a0f; color:#e4e6eb; }
a { color:#6ab2f2; text-decoration:none; }
a:hover { text-decoration:underline; }
.header { background:#111119; padding:16px 24px; border-bottom:1px solid #1e1e2e; display:flex; align-items:center; gap:16px; position:sticky; top:0; z-index:10; }
.header h1 { font-size:18px; color:#6ab2f2; }
.header .back { color:#8696a4; font-size:14px; }
.header .lang-switch { margin-left:auto; font-size:13px; color:#8696a4; }
.container { max-width:900px; margin:0 auto; padding:24px; }
.breadcrumb { color:#8696a4; font-size:13px; margin-bottom:20px; }
.breadcrumb a { color:#6ab2f2; }
.level-badge { display:inline-block; padding:4px 12px; border-radius:20px; font-size:12px; font-weight:600; margin-bottom:16px; }
.level-1 { background:rgba(74,222,128,0.15); color:#4ade80; }
.level-2 { background:rgba(96,165,250,0.15); color:#60a5fa; }
.level-3 { background:rgba(245,158,11,0.15); color:#f59e0b; }
.level-4 { background:rgba(239,68,68,0.15); color:#ef4444; }
.level-5 { background:rgba(168,85,247,0.15); color:#a855f7; }
h2 { font-size:28px; margin-bottom:8px; }
.desc { color:#8696a4; font-size:15px; line-height:1.7; margin-bottom:24px; }
.detail-list { list-style:none; padding:0; }
.detail-list li { padding:10px 16px; margin-bottom:6px; border-radius:8px; background:#111119; border-left:3px solid #2b5278; font-size:14px; line-height:1.5; color:#e4e6eb; }
.detail-list li::before { content:'\2192 '; color:#6ab2f2; }
.section-title { font-size:16px; color:#8696a4; margin:24px 0 12px; text-transform:uppercase; letter-spacing:1px; }
.related-topics { display:flex; gap:8px; flex-wrap:wrap; margin-top:8px; }
.related-topics a { display:inline-block; background:#111119; border:1px solid #1e1e2e; padding:6px 14px; border-radius:8px; font-size:13px; color:#6ab2f2; }
.related-topics a:hover { background:#1e1e2e; text-decoration:none; }
.nav-links { display:flex; justify-content:space-between; margin-top:30px; padding-top:20px; border-top:1px solid #1e1e2e; }
.nav-links a { color:#6ab2f2; font-size:14px; }
.nav-links .disabled { color:#333; }
.topic-grid { display:grid; grid-template-columns:repeat(auto-fill, minmax(260px, 1fr)); gap:12px; margin-top:16px; }
.topic-card { background:#111119; border-radius:12px; padding:18px; border-left:3px solid #2b5278; display:block; transition:background 0.15s; }
.topic-card:hover { background:#1a1a2e; text-decoration:none; }
.topic-card h3 { color:#e4e6eb; font-size:15px; margin-bottom:4px; }
.topic-card .sub { color:#8696a4; font-size:13px; }
.footer { text-align:center; padding:30px; color:#8696a4; font-size:12px; margin-top:30px; border-top:1px solid #1e1e2e; }
.overview { margin-bottom:28px; }
.overview p { color:#c4c6cb; font-size:15px; line-height:1.8; margin-bottom:14px; }
.terms-grid { display:grid; gap:10px; margin-top:12px; }
.term-card { background:#111119; border:1px solid #1e1e2e; border-radius:10px; padding:14px 18px; }
.term-card strong { color:#6ab2f2; font-size:14px; }
.term-card span { color:#c4c6cb; font-size:13px; display:block; margin-top:4px; line-height:1.5; }
.tip-box { background:linear-gradient(135deg, rgba(106,178,242,0.06), rgba(106,178,242,0.02)); border:1px solid rgba(106,178,242,0.15); border-radius:10px; padding:16px 20px; margin-top:12px; }
.tip-box li { color:#c4c6cb; font-size:14px; line-height:1.6; margin-bottom:8px; list-style:none; }
.tip-box li::before { content:'üí° '; }
.detail-card { background:#111119; border-radius:10px; padding:16px 18px; margin-bottom:8px; border-left:3px solid #2b5278; }
.detail-card .dt { color:#e4e6eb; font-size:14px; font-weight:600; margin-bottom:4px; }
.detail-card .dd { color:#9ca3af; font-size:13px; line-height:1.6; }
.detail-card .dl { margin-top:6px; }
.detail-card .dl a { font-size:12px; color:#6ab2f2; background:rgba(106,178,242,0.08); padding:3px 10px; border-radius:6px; display:inline-block; margin-right:6px; margin-top:4px; }
.detail-card .dl a:hover { background:rgba(106,178,242,0.15); text-decoration:none; }
</style>
</head>
<body>
<div class="header">
  <a href="../../index.html" class="back">&larr; Back to Course</a>
  <h1>Basic Theory</h1>
  <a href="../../../uk/basic-theory/level-1/generative-ai.html" class="lang-switch">üá∫üá¶ –£–∫—Ä–∞—ó–Ω—Å—å–∫–∞</a>
</div>
<div class="container">
  <div class="breadcrumb"><a href="../../index.html">Course</a> / <a href="../index.html">Basic Theory</a> / <a href="index.html">Level 1</a> / Generative AI</div>
  <span class="level-badge level-1">üå± Level 1 ‚Äî Beginner</span>
  <h2>Generative AI</h2>
  <p class="desc">Introduction to generative artificial intelligence - what it is, how it works, and why it matters.</p>

  <div class="overview">
    <p>Generative AI is a class of artificial intelligence systems that can create new content ‚Äî text, images, audio, video, and code ‚Äî rather than simply analyzing or classifying existing data. Unlike traditional machine learning models that predict labels or numbers, generative models learn the underlying patterns and distribution of their training data, then produce entirely new outputs that follow those same patterns.</p>
    <p>The field exploded into mainstream awareness with the release of ChatGPT in November 2022, but the foundations were laid years earlier with the Transformer architecture (2017), GPT-1 (2018), and the steady scaling of models that revealed emergent abilities at larger sizes. Today, generative AI powers everything from coding assistants to image generators, and understanding how it works is the essential starting point for anyone working with modern AI tools.</p>
    <p>Generative AI operates across multiple modalities. Large Language Models (LLMs) like GPT-4 and Claude generate text. Diffusion models like Stable Diffusion and DALL-E create images. Models like Sora generate video, while Whisper and similar systems handle audio. Increasingly, multimodal models combine several of these capabilities in a single system.</p>
  </div>
  <div class="section-title">Key Topics Covered</div>
  <div class="detail-cards">
    <div class="detail-card"><div class="dt">Generative vs Traditional AI/ML</div><div class="dd">Traditional AI classifies or predicts from data. Generative AI creates new content ‚Äî text, images, code ‚Äî by learning patterns from training data and producing novel outputs.</div><div class="dl"><a href="../level-1/data-classification.html">Data Type Classification</a></div></div>
    <div class="detail-card"><div class="dt">Key Generative Modalities</div><div class="dd">Text (LLMs like GPT, Claude), images (diffusion models like DALL-E, Midjourney), audio (Whisper, TTS), video (Sora, Runway), and code (Codex, StarCoder). Each modality uses different architectures.</div><div class="dl"><a href="diffusion-models.html">Diffusion Models</a><a href="multimodality.html">Multimodality</a></div></div>
    <div class="detail-card"><div class="dt">History of Generative AI</div><div class="dd">GPT-1 (2018, 117M params) ‚Üí GPT-2 (2019, 1.5B) ‚Üí GPT-3 (2020, 175B) ‚Üí ChatGPT (Nov 2022, public launch) ‚Üí GPT-4 (2023, multimodal). Each step brought qualitative leaps in capability.</div><div class="dl"><a href="llm-and-gpt.html">LLM and GPT</a></div></div>
    <div class="detail-card"><div class="dt">Generative vs Discriminative Models</div><div class="dd">Discriminative models learn decision boundaries (cat vs dog). Generative models learn the full data distribution and can sample new examples from it. LLMs are generative ‚Äî they model the probability of text.</div></div>
    <div class="detail-card"><div class="dt">The Transformer Architecture</div><div class="dd">The 2017 &quot;Attention Is All You Need&quot; paper introduced self-attention, enabling parallel processing of sequences. Virtually all modern generative AI ‚Äî text, image, video ‚Äî builds on this architecture.</div><div class="dl"><a href="../level-3/neural-networks.html">Neural Networks</a><a href="../level-3/model-types.html">Model Types</a></div></div>
    <div class="detail-card"><div class="dt">Pre-training at Scale</div><div class="dd">Models are trained on trillions of tokens from the internet ‚Äî books, websites, code repos, scientific papers. This phase costs millions of dollars and produces a &quot;foundation model&quot; with general capabilities.</div><div class="dl"><a href="foundation-models.html">Foundation Models</a><a href="../level-3/data-to-model.html">Data to Model</a></div></div>
    <div class="detail-card"><div class="dt">Emergent Abilities</div><div class="dd">At certain scales, models suddenly gain capabilities not present in smaller versions: in-context learning, chain-of-thought reasoning, code generation. These emerge from scale, not explicit programming.</div><div class="dl"><a href="reasoning.html">Reasoning</a></div></div>
    <div class="detail-card"><div class="dt">Real-World Applications</div><div class="dd">Software development (AI pair programming, code review), content creation (writing, design), healthcare (drug discovery), education (tutoring), finance (analysis), legal (document review).</div></div>
    <div class="detail-card"><div class="dt">Open vs Closed Ecosystem</div><div class="dd">Closed models (GPT-4, Claude) offer superior performance via API. Open-weight models (Llama, Qwen, Mistral) can be run locally, fine-tuned, and inspected. Both ecosystems are thriving.</div><div class="dl"><a href="big-players.html">The Big Players</a><a href="../level-4/api-providers.html">API Providers</a></div></div>
    <div class="detail-card"><div class="dt">Current Limitations</div><div class="dd">Hallucinations (confident but wrong outputs), reasoning gaps (failing on novel logic), context constraints (limited working memory), lack of real-time knowledge, and inability to truly &quot;understand.&quot;</div><div class="dl"><a href="../level-2/hallucination.html">Hallucinations</a><a href="../level-2/context.html">Context</a></div></div>
  </div>

  <div class="section-title">How Generative AI Works</div>
  <ul class="detail-list">
      <li>Models learn statistical patterns from billions of text/image examples during pre-training</li>
      <li>Text generation works by predicting the next token (word piece) in a sequence, one at a time</li>
      <li>Image generation (diffusion) works by learning to remove noise from random static, guided by text descriptions</li>
      <li>Temperature and sampling parameters control creativity vs determinism in outputs</li>
      <li>Models have no true understanding ‚Äî they are sophisticated pattern matchers operating on statistical regularities</li>
      <li>Fine-tuning and RLHF align raw model capabilities with human preferences and safety</li>
  </ul>

  <div class="section-title">Impact by Industry</div>
  <ul class="detail-list">
      <li>Software development: AI pair programming, code generation, automated testing, debugging</li>
      <li>Content &amp; media: automated writing, image/video creation, personalized content</li>
      <li>Healthcare: drug discovery, medical imaging analysis, clinical documentation</li>
      <li>Education: personalized tutoring, automated grading, content creation</li>
      <li>Finance: fraud detection, report generation, risk analysis</li>
      <li>Legal: document review, contract analysis, research assistance</li>
  </ul>

  <div class="section-title">Key Terms</div>
  <div class="terms-grid">
    <div class="term-card"><strong>Generative AI</strong><span>AI systems that create new content (text, images, code) rather than just analyzing existing data.</span></div>
    <div class="term-card"><strong>Foundation Model</strong><span>A large model pre-trained on broad data that serves as a base for many downstream tasks.</span></div>
    <div class="term-card"><strong>Transformer</strong><span>The neural network architecture (2017) that powers virtually all modern generative AI.</span></div>
    <div class="term-card"><strong>Pre-training</strong><span>The initial phase of training a model on massive datasets before task-specific adaptation.</span></div>
    <div class="term-card"><strong>Emergent Abilities</strong><span>Capabilities that appear suddenly in models only when they reach a certain scale.</span></div>
  </div>

  <div class="section-title">Practical Tips</div>
  <div class="tip-box"><ul>
    <li>Start by experimenting with ChatGPT or Claude to build intuition before diving into technical details</li>
    <li>Remember that generative AI is probabilistic ‚Äî the same prompt can produce different outputs each time</li>
    <li>Understanding the difference between generative and discriminative AI helps you choose the right tool for each task</li>
  </ul></div>

    <div class="section-title">Related Community Discussions</div>
    <div class="related-topics">
      <a href="#">Feed</a>
      <a href="#">AI Digest</a>
    </div>

  <div class="nav-links">
    <span class="disabled">&larr;</span>
    <a href="big-players.html">The Big Players &rarr;</a>
  </div>
</div>
<div class="footer"><a href="../../index.html">&larr; Back to Course</a></div>
</body>
</html>