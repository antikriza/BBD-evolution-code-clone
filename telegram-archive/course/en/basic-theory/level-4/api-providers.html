<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>API Providers - Basic Theory</title>
<style>
* { margin:0; padding:0; box-sizing:border-box; }
body { font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, sans-serif; background:#0a0a0f; color:#e4e6eb; }
a { color:#6ab2f2; text-decoration:none; }
a:hover { text-decoration:underline; }
.header { background:#111119; padding:16px 24px; border-bottom:1px solid #1e1e2e; display:flex; align-items:center; gap:16px; position:sticky; top:0; z-index:10; }
.header h1 { font-size:18px; color:#6ab2f2; }
.header .back { color:#8696a4; font-size:14px; }
.header .lang-switch { margin-left:auto; font-size:13px; color:#8696a4; }
.container { max-width:900px; margin:0 auto; padding:24px; }
.breadcrumb { color:#8696a4; font-size:13px; margin-bottom:20px; }
.breadcrumb a { color:#6ab2f2; }
.level-badge { display:inline-block; padding:4px 12px; border-radius:20px; font-size:12px; font-weight:600; margin-bottom:16px; }
.level-1 { background:rgba(74,222,128,0.15); color:#4ade80; }
.level-2 { background:rgba(96,165,250,0.15); color:#60a5fa; }
.level-3 { background:rgba(245,158,11,0.15); color:#f59e0b; }
.level-4 { background:rgba(239,68,68,0.15); color:#ef4444; }
.level-5 { background:rgba(168,85,247,0.15); color:#a855f7; }
h2 { font-size:28px; margin-bottom:8px; }
.desc { color:#8696a4; font-size:15px; line-height:1.7; margin-bottom:24px; }
.detail-list { list-style:none; padding:0; }
.detail-list li { padding:10px 16px; margin-bottom:6px; border-radius:8px; background:#111119; border-left:3px solid #2b5278; font-size:14px; line-height:1.5; color:#e4e6eb; }
.detail-list li::before { content:'\2192 '; color:#6ab2f2; }
.section-title { font-size:16px; color:#8696a4; margin:24px 0 12px; text-transform:uppercase; letter-spacing:1px; }
.related-topics { display:flex; gap:8px; flex-wrap:wrap; margin-top:8px; }
.related-topics a { display:inline-block; background:#111119; border:1px solid #1e1e2e; padding:6px 14px; border-radius:8px; font-size:13px; color:#6ab2f2; }
.related-topics a:hover { background:#1e1e2e; text-decoration:none; }
.nav-links { display:flex; justify-content:space-between; margin-top:30px; padding-top:20px; border-top:1px solid #1e1e2e; }
.nav-links a { color:#6ab2f2; font-size:14px; }
.nav-links .disabled { color:#333; }
.topic-grid { display:grid; grid-template-columns:repeat(auto-fill, minmax(260px, 1fr)); gap:12px; margin-top:16px; }
.topic-card { background:#111119; border-radius:12px; padding:18px; border-left:3px solid #2b5278; display:block; transition:background 0.15s; }
.topic-card:hover { background:#1a1a2e; text-decoration:none; }
.topic-card h3 { color:#e4e6eb; font-size:15px; margin-bottom:4px; }
.topic-card .sub { color:#8696a4; font-size:13px; }
.footer { text-align:center; padding:30px; color:#8696a4; font-size:12px; margin-top:30px; border-top:1px solid #1e1e2e; }
.overview { margin-bottom:28px; }
.overview p { color:#c4c6cb; font-size:15px; line-height:1.8; margin-bottom:14px; }
.terms-grid { display:grid; gap:10px; margin-top:12px; }
.term-card { background:#111119; border:1px solid #1e1e2e; border-radius:10px; padding:14px 18px; }
.term-card strong { color:#6ab2f2; font-size:14px; }
.term-card span { color:#c4c6cb; font-size:13px; display:block; margin-top:4px; line-height:1.5; }
.tip-box { background:linear-gradient(135deg, rgba(106,178,242,0.06), rgba(106,178,242,0.02)); border:1px solid rgba(106,178,242,0.15); border-radius:10px; padding:16px 20px; margin-top:12px; }
.tip-box li { color:#c4c6cb; font-size:14px; line-height:1.6; margin-bottom:8px; list-style:none; }
.tip-box li::before { content:'üí° '; }
.detail-card { background:#111119; border-radius:10px; padding:16px 18px; margin-bottom:8px; border-left:3px solid #2b5278; }
.detail-card .dt { color:#e4e6eb; font-size:14px; font-weight:600; margin-bottom:4px; }
.detail-card .dd { color:#9ca3af; font-size:13px; line-height:1.6; }
.detail-card .dl { margin-top:6px; }
.detail-card .dl a { font-size:12px; color:#6ab2f2; background:rgba(106,178,242,0.08); padding:3px 10px; border-radius:6px; display:inline-block; margin-right:6px; margin-top:4px; }
.detail-card .dl a:hover { background:rgba(106,178,242,0.15); text-decoration:none; }
</style>
</head>
<body>
<div class="header">
  <a href="../../index.html" class="back">&larr; Back to Course</a>
  <h1>Basic Theory</h1>
  <a href="../../../uk/basic-theory/level-4/api-providers.html" class="lang-switch">üá∫üá¶ –£–∫—Ä–∞—ó–Ω—Å—å–∫–∞</a>
</div>
<div class="container">
  <div class="breadcrumb"><a href="../../index.html">Course</a> / <a href="../index.html">Basic Theory</a> / <a href="index.html">Level 4</a> / API Providers</div>
  <span class="level-badge level-4">üöÄ Level 4 ‚Äî Master</span>
  <h2>API Providers</h2>
  <p class="desc">Cloud API providers for accessing AI models without local hardware.</p>

  <div class="overview">
    <p>API providers offer cloud-hosted AI models accessible via HTTP APIs ‚Äî no hardware, no model management, pay-per-use pricing. The big three (OpenAI, Anthropic, Google) develop their own frontier models, while inference providers (Together AI, Groq, Fireworks) host open-source models at competitive prices. Aggregators like OpenRouter provide a single API for all providers.</p>
    <p>Choosing a provider involves balancing model quality, latency, cost, and features. OpenAI offers the broadest ecosystem, Anthropic excels at complex reasoning and safety, Google provides the largest context windows. For open models, inference providers can be 5-10x cheaper than the big three. Understanding the landscape helps you optimize for your specific use case.</p>
  </div>
  <div class="section-title">Key Topics Covered</div>
  <div class="detail-cards">
    <div class="detail-card"><div class="dt">OpenAI API</div><div class="dd">GPT-4o, GPT-4-turbo, o1/o3 reasoning models. The largest ecosystem: assistants, fine-tuning, image generation (DALL-E), speech-to-text (Whisper), embeddings. The default choice for most projects.</div><div class="dl"><a href="../level-1/foundation-models.html">Foundation Models</a></div></div>
    <div class="detail-card"><div class="dt">Anthropic API</div><div class="dd">Claude Opus, Sonnet, and Haiku models. Excels at complex analysis, coding, and long-context tasks (200K tokens). Features: tool use, vision, prompt caching, batch API. Known for safety and instruction-following.</div><div class="dl"><a href="tool-use.html">Tool Use</a></div></div>
    <div class="detail-card"><div class="dt">Google AI (Gemini)</div><div class="dd">Gemini Pro and Ultra with 1M+ token context windows. Gemini API for developers, Vertex AI for enterprise. Multimodal native: text, images, video, audio in one model. Competitive pricing.</div><div class="dl"><a href="../level-1/multimodality.html">Multimodality</a></div></div>
    <div class="detail-card"><div class="dt">OpenRouter</div><div class="dd">Unified API gateway for 100+ models across all major providers. Single API key, consistent format, automatic fallbacks. Great for comparing models or switching providers without code changes.</div></div>
    <div class="detail-card"><div class="dt">Together AI</div><div class="dd">Leading open-source model hosting. Runs Llama, Mixtral, Qwen, and other open models at low cost. Fine-tuning service included. Often 5-10x cheaper than frontier model APIs for similar-quality open models.</div></div>
    <div class="detail-card"><div class="dt">Groq</div><div class="dd">Specialized inference provider using custom LPU chips. Extremely fast inference (500+ tokens/second) for supported models. Best for latency-critical applications where speed matters most.</div><div class="dl"><a href="hardware.html">Hardware Basics</a></div></div>
    <div class="detail-card"><div class="dt">Fireworks AI</div><div class="dd">Fast inference with function calling optimization. Strong at serving fine-tuned models and compound AI systems. Good balance of speed, cost, and features for production workloads.</div></div>
    <div class="detail-card"><div class="dt">Pricing Models</div><div class="dd">Pay-per-token (most providers), pay-per-second (some inference), subscription tiers (OpenAI Plus). Input tokens are cheaper than output. Prompt caching (Anthropic, Google) reduces costs for repeated prefixes.</div><div class="dl"><a href="../level-2/token.html">Token</a></div></div>
    <div class="detail-card"><div class="dt">Cost Optimization</div><div class="dd">Use smaller models for simple tasks (Haiku, GPT-4o-mini). Cache prompts for repeated contexts. Batch non-urgent requests (50% discount). Use open models via inference providers when frontier quality is not needed.</div></div>
    <div class="detail-card"><div class="dt">Provider Selection Strategy</div><div class="dd">Prototype: OpenAI (best docs, widest support). Complex reasoning: Anthropic Claude. Long context: Google Gemini. Budget: Together AI or Groq. Production: start with one, add OpenRouter for fallback.</div></div>
  </div>

  <div class="section-title">Key Terms</div>
  <div class="terms-grid">
    <div class="term-card"><strong>Inference Provider</strong><span>Service that hosts and runs AI models, offering API access without requiring your own hardware or model management.</span></div>
    <div class="term-card"><strong>Token Pricing</strong><span>Pay-per-use model where costs are calculated based on number of input and output tokens processed.</span></div>
    <div class="term-card"><strong>Prompt Caching</strong><span>Provider feature that reduces costs and latency by caching repeated prompt prefixes across API calls.</span></div>
    <div class="term-card"><strong>API Gateway</strong><span>Unified access point (like OpenRouter) that routes requests to multiple AI providers through a single API.</span></div>
  </div>

  <div class="section-title">Practical Tips</div>
  <div class="tip-box"><ul>
    <li>Use GPT-4o-mini or Claude Haiku for simple tasks ‚Äî they are 10-20x cheaper than frontier models and fast enough for most use cases</li>
    <li>Always implement provider fallbacks in production ‚Äî OpenRouter makes this easy with automatic routing between providers</li>
    <li>Enable prompt caching on Anthropic and Google when you have repeated system prompts ‚Äî it can cut costs by 90% for cached portions</li>
  </ul></div>

    <div class="section-title">Related Community Discussions</div>
    <div class="related-topics">
      <a href="#">Agents &amp; Tools</a>
    </div>

  <div class="nav-links">
    <a href="hardware.html">&larr; Hardware Basics</a>
    <span class="disabled">&rarr;</span>
  </div>
</div>
<div class="footer"><a href="../../index.html">&larr; Back to Course</a></div>
</body>
</html>